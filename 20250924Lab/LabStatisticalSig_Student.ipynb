{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5745021e-abd6-44eb-b709-14a70f6c21d0",
   "metadata": {},
   "source": [
    "# CP201A Lab: Testing for Statistical Significance\n",
    "Fall 2025\n",
    "\n",
    "# Learning Objectives\n",
    "* Learn how to use .loc to select subsets of a dataframe\n",
    "* Learn how to test ACS-provided estimates for statistical significance\n",
    "* Optional: Learn how to make graphs with MOE bars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33133d2d-95dd-480b-bdd1-22379e6d0b58",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "# 0. Before we begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7485b84b-3ce1-40a3-8028-9dc36df9757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries and modules we need\n",
    "import pandas as pd\n",
    "from census import Census\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340bea61-b246-4def-a7d0-012c775f76d6",
   "metadata": {},
   "source": [
    "## 0.1 Using `.loc` to select data\n",
    "\n",
    "`.loc` (aka location) is a Pandas feature that allows us to select very specific subsets of dataframe. Remember how we used indexes to slice up lists in our first Python lab? `.loc` operates very similarly! It may seem a bit abstract right now, but we'll be using this feature later on in this notebook.\n",
    "\n",
    "Here is the basic format: `dataframe.loc[row_index, column_name]` But depending on what we want to select, we do not always have to specify the row index or column name. \n",
    "\n",
    "Let's dive right in and explore its functionality!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abd09f1-eb5b-4cda-9212-f803e6b51d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's some sample data we'll use for this tutorial\n",
    "flowers = pd.DataFrame({'Type': ['Orchid', 'Rose', 'Carnation', 'Daffodil'],\n",
    "                        'Count': [1, 15, 4, 21], \n",
    "                        'Color': ['Red', 'White', 'Orange', 'Yellow']})\n",
    "flowers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcb4b47-53ad-49ad-b8ea-1fc64fe4d7ff",
   "metadata": {},
   "source": [
    "#### **A. `.loc` can select very particular slices of a dataframe**\n",
    "\n",
    "<img src=\"excel_example_a.png\" width=\"300\">\n",
    "\n",
    "\n",
    "If we think of our dataframe as a table in Excel, then we are just selecting cells A1 through B5. \n",
    "\n",
    "The following code is telling Python to extract every row (`:` means every row) for the columns `'Type'` and `'Color'`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5f29ce-5978-44d0-b508-06f3b54d2919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using .loc, we can extract all the rows (:) in a particular column(s) ('Type', 'Color')\n",
    "flowers.loc[:, ['Type', 'Color']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed35b33f-e732-431f-8c40-9fd595cca991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Of course, we can do this in an even simpler way\n",
    "flowers[['Type', 'Color']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80b6403-e30d-4488-a62d-1d68b3be486b",
   "metadata": {},
   "source": [
    "If we instead want only the first two rows, or cells A1 through B3 in the Excel table, then we change `:` to `0:1` which indicates that we want rows with the index 0 and 1. \n",
    "\n",
    "Notice that unlike list slicing, the **second index number is inclusive.** Also note that **column headers are not given a row index** because Pandas knows to treat that \"row\" of data as a header. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a536c7-01b8-4232-9aa7-a6634d2b6d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we only wanted to select the first two rows, we would use 0:1 (note that the index is inclusive)\n",
    "flowers.loc[0:1, ['Type', 'Color']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a57ae95-c05a-4284-80ea-da7e5324baac",
   "metadata": {},
   "source": [
    "#### **B. `.loc` can select rows based on their index** \n",
    "\n",
    "<img src=\"excel_example_b.png\" width=\"300\">\n",
    "\n",
    "We don't have to specify a column name either. If we give `.loc` only an index number, then it will give us all columns for the corresponding row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addf7b2c-853c-443a-98fe-7e013e9e20d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .loc also allows us to select specific row(s) based on their index\n",
    "flowers.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1115fc-2d6c-42c2-8fcc-ec21e94fab80",
   "metadata": {},
   "source": [
    "But unless we know the exact index of the row that we want to extract, then it's not very useful to use index numbers. To get around this, we can **change the index of our dataframe to something meaningful.** From there, we can use the values of the new index to subset our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198eb139-d97b-4a5a-aff2-89805f704c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowers = flowers.set_index('Type')\n",
    "flowers\n",
    "\n",
    "# See that the index of the table (the bold column on the far left) is now the type of flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a62a69-78a7-4a0d-a2dc-c60a6511567a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we can use .loc to select by type.\n",
    "flowers.loc['Orchid']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086baf1a-bcd1-4820-ba64-f07b231e06f9",
   "metadata": {},
   "source": [
    "Previously, we could have used `flowers.loc[0, 'Count']` to extract this specific value. But being able to use `Orchid` as our index is much more intuitive. This feature can be incredibly useful because I may want to pull out a very specific value and then store it in a variable to use later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d982173-ff8f-4691-ad7d-514763fc1389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we extract the count for the orchid row.\n",
    "flowers.loc['Orchid', 'Count']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff6f81d-96a1-4c07-bad8-aefd74ceb982",
   "metadata": {},
   "source": [
    "#### **C. `.loc` can select rows based on one or more conditions** \n",
    "\n",
    "<img src=\"excel_example_c.png\" width=\"400\">\n",
    "\n",
    "Finally, we can use `.loc` to filter data using one or more conditions just like we can use the filter function on Excel to select specific column values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da263cb-e4db-440d-a6b9-e1f41b4b6fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line of code is asking Python to give us only the rows where the corresponding value in the 'Count' column are greater than 10\n",
    "flowers.loc[flowers['Count']>10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8742122b-85cc-4e1e-9e5b-a40dde227a4b",
   "metadata": {},
   "source": [
    "We can also specify multiple conditions. Note that a **double equal sign (`==`) checks for equivalence**. In other words, we are checking that the value in the `'Color'` column is equal to `'Yellow'`. Also note that you must put parentheses around each condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbed88a-c711-4b11-bb6a-504ed72e7207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# & means AND, meaning both conditions must be satisfied\n",
    "flowers.loc[(flowers['Count']>10) & (flowers['Color']=='Yellow')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f349d4ef-7971-452d-ab9a-a5790d9fe679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | means OR,  meaning either condition can be satisfied\n",
    "flowers.loc[(flowers['Count']>10) | (flowers['Color']=='Yellow')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a62589-441e-47eb-a1d7-3ee5006fbd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Use .loc to extract the color corresponding to carnation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50f41b5-cce4-4aa9-a198-877976eef89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Use .loc to find the rows where the count of flowers is less than 5 or more than 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0506c26-0e4a-40a5-b1af-84b925940356",
   "metadata": {},
   "source": [
    "-------------------------\n",
    "# 1. Data\n",
    "\n",
    "**There are 2 options for the data we'll use in today's lab:** \n",
    "* **Option A**: If you already have a cleaned table with aggregated, neighborhood-level estimates, then go ahead and use that data. Follow the instructions in the Option A section. \n",
    "* **Option B**: If you do not yet have a cleaned table with aggregated, neighorhood-level estimates, you can work with the dataset we've prepared for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95bb12e-c728-4d14-b6a7-dfc8ecb3e85c",
   "metadata": {},
   "source": [
    "-------------------------\n",
    "### **Option A**\n",
    "\n",
    "If you haven't already, go to the .ipynb file where you cleaned your data and export each dataframe as a csv file. Here is some sample code of how to do this: \n",
    "\n",
    "`df_out.to_csv('file_name.csv', index=False)`\n",
    "\n",
    "Then import that csv into this file using the following code block: \n",
    "\n",
    "`new_df_name = pd.read_csv('file_name.csv')`\n",
    "\n",
    "**Then skip down to section 2.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cf2bee-efa4-48d5-ad58-f4adc3ef130e",
   "metadata": {},
   "source": [
    "-------------------------\n",
    "### **Option B**\n",
    "To switch it up from last week's labs, we'll use the following data for comparisons today:\n",
    "\n",
    "* Table: [B25070](https://api.census.gov/data/2022/acs/acs1/groups/B25070.html)\n",
    "* Table Name: Gross Rent as a Percentage of Household Income in the Past 12 Months\n",
    "* Geography: The neighborhood of Fruitvale and the city of Oakland\n",
    "* Universe: Renter-occupied housing units\n",
    "* Dataset: [2023 ACS 1-year estimates](https://api.census.gov/data/2023/acs/acs1/examples.html)\n",
    "\n",
    "We downloaded the following variables, and renamed them as shown below:\n",
    "\n",
    "|     Old Name                                           |     New Name         |\n",
    "|--------------------------------------------------------|----------------------|\n",
    "|     Estimate!!Total:                                   |     total            |\n",
    "|     Margin of Error!!Total:                            |     total_moe        |\n",
    "|     Estimate!!Total:!!30.0 to 34.9   percent           |     rb_30to34        |\n",
    "|     Margin of Error!!Total:!!30.0 to   34.9 percent    |     rb_30to34_moe    |\n",
    "|     Estimate!!Total:!!35.0 to 39.9   percent           |     rb_35to39        |\n",
    "|     Margin of Error!!Total:!!35.0 to   39.9 percent    |     rb_35to39_moe    |\n",
    "|     Estimate!!Total:!!40.0 to 49.9   percent           |     rb_40to49        |\n",
    "|     Margin of Error!!Total:!!40.0 to   49.9 percent    |     rb_40to49_moe    |\n",
    "|     Estimate!!Total:!!50.0 percent or   more           |     rb_mt50          |\n",
    "|     Margin of Error!!Total:!!50.0   percent or more    |     rb_mt50_moe      |\n",
    "\n",
    "We have done all the steps from last week's lab:\n",
    "- We created a new variable rent_burdened by combining the four estimates of over 30 percent spent on rent; then a second severely_rent_burdened which is severely rent burdened, meaning that they spent more than 50 percent on rent (note that these are **NOT** mutually exclusive)\n",
    "- We aggregated the MOEs associated with those estimates, using the square root sum of squares formula\n",
    "- We calculated the percent of rent burdened households\n",
    "- We calculated the derived proportion MOE\n",
    "- And we put both the neighborhood and city results into one .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a097b71-83a6-4683-bb5e-fabd2768c161",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'm going to limit the display to just one decimal point - it will make things easier to read\n",
    "pd.options.display.float_format = \"{:.3f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b625a9b6-7c40-45b2-b7f6-303cdef37622",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's bring in the .csv and look at it\n",
    "df = pd.read_csv('rentburden_2023.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d111c7d-b37f-496a-93a6-a912d738ca08",
   "metadata": {},
   "source": [
    "------------------------\n",
    "# 2. Testing for statistically significant differences\n",
    "\n",
    "Depending on which data option you selected, follow the built-in exercises in this section based on the following: \n",
    "* **Option A**: Use your own data to test whether there are statistically significant differences between two categories in your data.\n",
    "* **Option B**: Use the data we loaded in and cleaned above to test whether there are statistically significant differences between renter cost burdens in Fruitvale and Oakland.\n",
    "    * For the exercises, pick something different in our cleaned dataset to compare. For example, you could try testing whether the percentage of severely rent burdened households is different.\n",
    "\n",
    "## 2.1 Calculating standard errors\n",
    "\n",
    "First we need to convert the 90% confidence level margins of error that come with the ACS data into standard errors. The formula to do so is $SE = \\frac{MOE_{ACS}}{1.645},$ where $MOE_{ACS}$ is the 90% margin of error provided for the ACS estimate.\n",
    "\n",
    "Let's calculate the standard error for the estimates of the percent of renters who are cost burdened. Try implementing this formula for this estimate's standard error now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662170c7-12bd-4ecc-b676-adcbd7602d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Create a new 'pct_rent_burdened_se' column based on 'pct_rent_burdened_moe'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd25e14d-11de-4024-b60c-378c1b23f5c0",
   "metadata": {},
   "source": [
    "We have quite a few margins of error in our DataFrame, and it would be nice to handle them all at once, rather than have to repeat ourselves several times. Because we've been diligent in our variable naming conventions, all our MOEs' column names end in `_moe`. Can we exploit this fact to efficiently convert them all to standard errors?\n",
    "\n",
    "...\n",
    "\n",
    "Yes. Of course we can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a3dce2-7a8e-4946-8a49-de24f971e316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through all column names\n",
    "for col in df.columns:\n",
    "    # Check whether each column name ends with '_moe', using a built-in string method\n",
    "    # `if '_moe' in col:` is another possibility, but what if we had a column named `pct_moebius` or something?\n",
    "    if col.endswith('_moe'):\n",
    "        # Replace '_moe' with '_se' but only at the end of the name, again using string subsetting\n",
    "        # col[:-4] selects all but the last four characters in col\n",
    "        df[col[:-4] + '_se'] = df[col] / 1.645\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c417fe70-a664-4f8f-a9a2-affd51c730b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise for Option A: Try it out with your own data!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34db31c8-49ab-4998-aa76-3f226f96654f",
   "metadata": {},
   "source": [
    "## 2.2 Implementing the two-sample t-test of means\n",
    "\n",
    "Let's review the formula for testing whether two sample estimates are statistically significantly different from each other:\n",
    "\n",
    "$$\\left|\\frac{\\hat{X}_1 - \\hat{X}_2}{\\sqrt{SE_1^2 + SE_2^2}}\\right| > Z_{CL},$$\n",
    "where:\n",
    "* $\\hat{X}_1$ and $\\hat{X}_2$ are the estimates we're comparing (the hat over the $X$ just means that the value is an estimate)\n",
    "* $SE_1$ and $SE_2$ are the corresponding *standard error* values, and\n",
    "* $Z_{CL}$ is the z-score associated with a given *confidence level* (1.645 for 90%, 1.96 for 95%, 2.576 for 99%).\n",
    "\n",
    "We have all our “ingredients” – we have the percent of renters who are cost burdened for each geography, as well as the associated standard error. Now we just need to implement this formula. It looks complicated, but we already know addition `+`, subtraction `-`, division `-`, and exponentiation `**` in Python. All we really need to complete the picture is how to take the *absolute value* of a number.\n",
    "\n",
    "The absolute value of a real number $x$ is the non-negative value of $x$, without regard to its sign. In math formulas, $|x|$ denotes an absolute value. In Python, the function `abs(x)` returns the value of `x` if `x` is non-negative, or `-x` if `x` is negative. So `abs(4)` is 4, and `abs(-10)` is 10.\n",
    "\n",
    "Try plugging in the numbers from the City of Oakland and Alameda County into the formula for testing significant differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de356e4-ef2a-4a4f-9ba2-7715b5896e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need to set a meaningful index because we want to use the index to select specific rows in our dataframe. \n",
    "# Recall how we set the index to flower 'type' in the .loc example above? We're doing the same thing here.\n",
    "df = df.set_index('NAME')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4fee32-047e-491e-9b9b-74ae2573513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplicity, I'll start by assigning the relevant cells from our DataFrame to variable names matching the formula above\n",
    "\n",
    "# To do this, we'll use .loc! And since we've set the index as the geography name, we can pass 'Fruitvale' to .loc.\n",
    "x1 = df.loc['Fruitvale', 'pct_rent_burdened']\n",
    "x2 = df.loc['Oakland city, California', 'pct_rent_burdened']\n",
    "se1 = df.loc['Fruitvale', 'pct_rent_burdened_se']\n",
    "se2 = df.loc['Oakland city, California', 'pct_rent_burdened_se']\n",
    "\n",
    "# Print x1 and x2, nicely formatted as percentages, to see how different they *appear* to be\n",
    "print(f'{x1:.2%}, {x2:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1261cf07-c21a-47fe-9b47-52dbbd2b15e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise for Option A and B: Calculate the z-score using the variables we just created above (i.e. x1, x2, etc.)\n",
    "\n",
    "zscore = 'put your equation here'\n",
    "print('Our z-score is:', zscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035fb445-7554-4df3-aa51-aa35ac55bfb6",
   "metadata": {},
   "source": [
    "**What does this z-value mean for our analysis?** Can we say the estimates are *statistically significantly different*? If so, at what confidence level?\n",
    "\n",
    "Remember if the absolute value of our z-score is greater than our critical value or, in other words, is located in the blue tail region of the below curve, we can **reject our null hypothesis** meaning there **is** a statistically significant difference between our two samples. Otherwise we **fail to reject our null hypothesis** meaning there **is not** a statistically significant difference.\n",
    "<img src=\"z_test_example.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43f7e93-453f-49ea-8157-fe17c46d5885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise for Option A: Try it out with your own data!\n",
    "# Exercise for Option B: Test whether the difference between the percent of households that are severely rent burdened is statistically significant\n",
    "\n",
    "\n",
    "# Make sure to interpret your z-value. What does it mean for your analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1975ec-330d-4ed1-9060-ddf5a32fa261",
   "metadata": {},
   "source": [
    "It would be nice if we could quickly check a given variable and pair of geographies for statistically significant differences. Try writing a function that takes in a DataFrame, a variable to check, and two jurisdictions to compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20856f5f-ebbc-4f04-8c0e-0a534f6cbce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_statistic(df, col, place_1, place_2):\n",
    "    '''Write a brief docstring - future you will thank past you.\n",
    "\n",
    "    Inputs:\n",
    "    - df (pd.DataFrame): the table of summary statistics and standard errors.\n",
    "      Columns must contain col and col + '_se'. Index must contain place_1\n",
    "      and place_2\n",
    "    - col (string): the column name to be compared across jurisdictions.\n",
    "    - place_1, place_2 (string): the jurisdictions whose values to compare.\n",
    "\n",
    "    Output:\n",
    "    The two-sample z-value (float) of the difference between the values of col\n",
    "    for place_1 and place_2.\n",
    "    '''\n",
    "    # Assign the relevant cells from df to variable names matching the formula\n",
    "    x1 = df.loc[place_1, col]\n",
    "    x2 = df.loc[place_2, col]\n",
    "    se1 = df.loc[place_1, col + '_se']\n",
    "    se2 = df.loc[place_2, col + '_se']\n",
    "\n",
    "    # Return the z-value\n",
    "    return abs((x1 - x2) / (se1**2 + se2**2)**0.5)\n",
    "\n",
    "# Try out your function on severely cost burdened renters in Berkeley and Oakland\n",
    "z_statistic(df, 'pct_rent_burdened', 'Fruitvale', 'Oakland city, California')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61740f9-c19b-4a23-8d70-5e7867784148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise for Option A and B: Try this function out with the same test that you ran above. See if you get the same z-value. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430cc4d8-26f0-423c-ac0f-3b5bff38b753",
   "metadata": {},
   "source": [
    "# 3. OPTIONAL: Plotting proportions with margins of error\n",
    "\n",
    "We are now going to plot the results of the previous exercise. We want to visualize the proportion of rental units that are occupied by cost-burdened households in these two geographies *AND visualize the margins of error.* \n",
    "\n",
    "As is often the case in Python, there are quite a few ways to plot data from a pandas DataFrame:\n",
    "* Pandas' built-in plotting (`df.plot`) is a quick-and-dirty tool that can often produce surprisingly good graphs with a little coaxing\n",
    "* `matplotlib.pyplot` is more flexible but also more verbose than `df.plot`\n",
    "* `seaborn` is great at producing complex statistical plots, including from raw data (rather than summary statistics)\n",
    "\n",
    "Today we are going to focus on `df.plot`, because it's the simplest and it gets the job done! Pandas' plotting uses `matplotlib` under the hood, so if you get into `matplotlib` later, you'll see some similarities to what we're doing today.  \n",
    "\n",
    "Note: you may need to install matplotlib in your conda environment.  Just open a new conda prompt, open your environment, and type \"conda install matplotlib\".\n",
    "\n",
    "Then, you can create a bar chart using a remarkably simple command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f105c81-7d24-4568-841e-b943eeee97a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.bar(y='pct_rent_burdened')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb3b5ec-db7f-4f24-a932-096d2e1f1f29",
   "metadata": {},
   "source": [
    "This is not half bad, for one short line of code! But because we're committed to high standards for data visualization, let's address a few issues:\n",
    "\n",
    "1. We need to show margins of error to visually indicate how exact our estimates are.\n",
    "2. The y-axis should be formatted as percentage points, not plain decimals.\n",
    "3. We don't need the legend, but we do need a chart title.\n",
    "4. We need a good *caption* for our chart.\n",
    "\n",
    "Let's tackle these, point by point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30154332-41eb-487e-94d0-2e3afdc08417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Show margins of error: df.plot.bar() accepts a `yerr` argument\n",
    "# that lets us specify which column to use for the width of margins of error\n",
    "df.plot.bar(y='pct_rent_burdened', yerr='pct_rent_burdened_moe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20979c12-9fe5-4e5e-b414-1a50ae29f6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Format the y-axis as percentage points: we need to store the result of\n",
    "# df.plot.bar() as an Axes object, then adjust some attributes of the object.\n",
    "# This is the hardest one, but matplotlib has a PercentFormatter that really helps\n",
    "# - see here for more details https://stackoverflow.com/a/36319915\n",
    "import matplotlib.ticker as mtick\n",
    "ax = df.plot.bar(y='pct_rent_burdened', yerr='pct_rent_burdened_moe')\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f0f286-578a-4435-9007-1736a7ad8339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Remove legend, add a title: we can set `legend=False` in df.plot.bar();\n",
    "# adding a legend means again modifying the Axes object as we did for #3\n",
    "ax = df.plot.bar(\n",
    "    y='pct_rent_burdened',\n",
    "    yerr='pct_rent_burdened_moe',\n",
    "    legend=False\n",
    ")\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0, 0))\n",
    "ax.set_title('Percent of Rental Units Occupied by Cost-Burdened Households')\n",
    "# You can use similar syntax to set x and y axis labels, if needed\n",
    "# I don't think we need them for this plot, though\n",
    "# ax.set_xlabel('Jurisdiction')\n",
    "# ax.set_ylabel('Percent of Rental Units')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126bda5d-8956-48c7-8aa5-d0b6833359bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus visualization option: sometimes a horizontal bar chart (df.plot.barh()) is nice.\n",
    "# We need to change yerr to xerr and ax.yaxis.set_major_formatter to ax.xaxis.set_major_formatter\n",
    "# (but we don't change 'y' to 'x', confusing!)\n",
    "# Also note I have specified additional keyword arguments `figsize`, `width`, and `color`;\n",
    "# other arguments also exist: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.barh.html\n",
    "ax = df.plot.barh(\n",
    "    y='pct_rent_burdened',\n",
    "    xerr='pct_rent_burdened_moe',\n",
    "    legend=False,\n",
    "    figsize=(6, 2),  # inches at 100 dpi\n",
    "    width=0.8,\n",
    "    color='firebrick',  # https://matplotlib.org/stable/gallery/color/named_colors.html\n",
    ")\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter(1.0, 0))\n",
    "ax.set_title('Percent of Rental Units Occupied by Cost-Burdened Households')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7265c0-80a8-42ba-94b3-5cff94d9af6b",
   "metadata": {},
   "source": [
    "As for issue #5, good captions for your graphs, this isn't really a Python question, because captions usually sit alongside the graph in whatever presentation/report preparation software (PowerPoint, Word, Canva, Google Slides, etc.) you use downstream of preparing the chart. But make sure your caption clearly indicates the source of your data, its vintage and universe, and definitions of any concepts or choices you made during your analysis. A good caption for this chart might look something like this:\n",
    "\n",
    "> Source: American Community Survey 2022 1-year estimates, Table B25070. Universe: Renter-occupied housing units. Notes: Rent burden is defined as those spending between 30-49.9% of their income on rent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04af9dd-3d86-48f3-ae51-ad46cba7f439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Exercise: Try plotting a different set of data (use your own data for Option A, try plotting severely rent burdened for Option B)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8c437f-8867-4368-860b-5824510873ab",
   "metadata": {},
   "source": [
    "# 4. Save your data\n",
    "\n",
    "You have this nice plot, and this lovely data table, but they're both \"stuck\" in this Jupyter notebook. Let's set them free!\n",
    "\n",
    "The easiest way to export a plot from a Jupyter notebook is to right-click the image, click \"Copy Output to Clipboard\", and paste the figure into your report/presentation or into an image editing program like Paint (Windows) or Preview (macOS). \n",
    "\n",
    "As for your data table, just save it as a CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f706fc6b-391b-42ad-9bca-a0b524913d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('lab_4_finished.csv')\n",
    "# Note no `index=False` this time because we set a meaningful index!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
